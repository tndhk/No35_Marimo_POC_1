{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# お弁当販売数予測 - bento9_opus_talk\n\nこのノートブックは marimoから変換されました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 全モジュールのインポート\nimport polars as pl\nimport pandas as pd\nimport altair as alt\nfrom pathlib import Path\nimport numpy as np\nimport lightgbm as lgb\nimport re\nimport jpholiday\nfrom datetime import datetime\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 訓練データの読み込み\ndata_path_train = Path(\"data/bento_train.csv\")\ndf_train = pl.read_csv(data_path_train, null_values=[\"--\"])\n\n# テストデータの読み込み\ndata_path_test = Path(\"data/bento_test.csv\")\ndf_test = pl.read_csv(data_path_test, null_values=[\"--\"])\n\nprint(f\"訓練データ: {df_train.shape[0]} 行 × {df_train.shape[1]} 列\")\nprint(f\"テストデータ: {df_test.shape[0]} 行 × {df_test.shape[1]} 列\")\nprint(f\"評価指標: RMSE（Root Mean Squared Error）\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 基本統計とデータ理解"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 基本統計量\ntrain_stats = df_train.describe()\ntrain_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 欠損値確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値確認\nnull_counts = df_train.null_count()\ntotal_rows = df_train.shape[0]\n\nnull_info = pl.DataFrame({\n    \"カラム\": list(null_counts.columns),\n    \"欠損数\": [null_counts[col][0] for col in null_counts.columns],\n    \"欠損率(%)\": [\n        round(null_counts[col][0] * 100 / total_rows, 2)\n        for col in null_counts.columns\n    ]\n}).filter(pl.col(\"欠損数\") > 0)\n\nnull_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 目的変数yの分布\nchart_y = alt.Chart(df_train.to_pandas()).mark_bar().encode(\n    alt.X(\"y:Q\", bin=alt.Bin(maxbins=30), title=\"販売数\"),\n    alt.Y(\"count()\", title=\"頻度\"),\n    tooltip=[\"count()\"]\n).properties(\n    width=600,\n    height=300,\n    title=\"販売数（y）の分布\"\n)\nchart_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 曜日別販売数\nweek_order = [\"月\", \"火\", \"水\", \"木\", \"金\", \"土\", \"日\"]\n\nchart_week = alt.Chart(df_train.to_pandas()).mark_boxplot().encode(\n    alt.X(\"week:N\", title=\"曜日\", sort=week_order),\n    alt.Y(\"y:Q\", title=\"販売数\"),\n    tooltip=[\"week\", \"y\"]\n).properties(\n    width=600,\n    height=300,\n    title=\"曜日別販売数の分布\"\n)\nchart_week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 特徴量エンジニアリング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 日付特徴量\ndef add_date_features(df):\n    return df.with_columns([\n        pl.col(\"datetime\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date\"),\n    ]).with_columns([\n        pl.col(\"date\").dt.year().alias(\"year\"),\n        pl.col(\"date\").dt.month().alias(\"month\"),\n        pl.col(\"date\").dt.day().alias(\"day\"),\n        pl.col(\"date\").dt.weekday().alias(\"weekday\"),  # 0=月, 6=日\n    ])\n\ndf_train_fe = add_date_features(df_train)\ndf_test_fe = add_date_features(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 祝日フラグ\ndef is_holiday(date_str):\n    try:\n        dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n        return 1 if jpholiday.is_holiday(dt) else 0\n    except:\n        return 0\n\ndf_train_fe2 = df_train_fe.with_columns([\n    pl.col(\"datetime\").map_elements(is_holiday, return_dtype=pl.Int64).alias(\"is_holiday\")\n])\n\ndf_test_fe2 = df_test_fe.with_columns([\n    pl.col(\"datetime\").map_elements(is_holiday, return_dtype=pl.Int64).alias(\"is_holiday\")\n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# カテゴリカル特徴量のエンコーディング\nweek_map = {\"月\": 0, \"火\": 1, \"水\": 2, \"木\": 3, \"金\": 4, \"土\": 5, \"日\": 6}\nweather_map = {\"快晴\": 0, \"晴れ\": 1, \"薄曇\": 2, \"曇\": 3, \"雨\": 4, \"雪\": 5, \"雷電\": 6}\n\ndf_train_fe3 = df_train_fe2.with_columns([\n    pl.col(\"week\").replace(week_map).cast(pl.Int64).alias(\"week_encoded\"),\n    pl.col(\"weather\").replace(weather_map).cast(pl.Int64).alias(\"weather_encoded\")\n])\n\ndf_test_fe3 = df_test_fe2.with_columns([\n    pl.col(\"week\").replace(week_map).cast(pl.Int64).alias(\"week_encoded\"),\n    pl.col(\"weather\").replace(weather_map).cast(pl.Int64).alias(\"weather_encoded\")\n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# soldout, paydayを数値型に変換\ndf_train_fe4 = df_train_fe3.with_columns([\n    pl.col(\"soldout\").cast(pl.Int64),\n    pl.col(\"payday\").fill_null(value=0).cast(pl.Int64)\n])\n\ndf_test_fe4 = df_test_fe3.with_columns([\n    pl.col(\"soldout\").cast(pl.Int64),\n    pl.col(\"payday\").fill_null(value=0).cast(pl.Int64)\n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値補完（訓練データの統計量を使用）\n# データリーク防止: テストデータの補完には必ず訓練データの中央値を使用\n\n# 訓練データで中央値を計算\ntrain_kcal_median = df_train_fe4[\"kcal\"].median()\ntrain_precipitation_median = df_train_fe4[\"precipitation\"].median()\ntrain_temp_median = df_train_fe4[\"temperature\"].median()\n\n# 訓練データの欠損値補完\ndf_train_filled = df_train_fe4.with_columns([\n    pl.col(\"kcal\").fill_null(value=train_kcal_median),\n    pl.col(\"precipitation\").fill_null(value=train_precipitation_median),\n    pl.col(\"temperature\").fill_null(value=train_temp_median)\n])\n\n# テストデータの欠損値補完（訓練データの統計量を使用）\ndf_test_filled = df_test_fe4.with_columns([\n    pl.col(\"kcal\").fill_null(value=train_kcal_median),\n    pl.col(\"precipitation\").fill_null(value=train_precipitation_median),\n    pl.col(\"temperature\").fill_null(value=train_temp_median)\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 欠損値処理後の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値処理確認\ntrain_nulls_after = df_train_filled.null_count().sum_horizontal()[0]\ntest_nulls_after = df_test_filled.null_count().sum_horizontal()[0]\n\nprint(f\"訓練データ欠損数: {train_nulls_after}\")\nprint(f\"テストデータ欠損数: {test_nulls_after}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量選択\nfeature_cols = [\n    \"year\", \"month\", \"day\", \"weekday\", \"is_holiday\",\n    \"week_encoded\", \"weather_encoded\",\n    \"soldout\", \"payday\",\n    \"kcal\", \"precipitation\", \"temperature\"\n]\n\nX_train = df_train_filled.select(feature_cols).to_pandas()\ny_train = df_train_filled.select(\"y\").to_pandas()[\"y\"]\nX_test = df_test_filled.select(feature_cols).to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. モデリング準備完了"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"訓練データ: {X_train.shape[0]} samples × {X_train.shape[1]} features\")\nprint(f\"テストデータ: {X_test.shape[0]} samples × {X_test.shape[1]} features\")\nprint(f\"特徴量リスト: {', '.join(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. モデリング - Ridge回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ridge回帰モデル\ntscv = TimeSeriesSplit(n_splits=5)\nridge = Ridge(alpha=1.0)\n\nridge_cv_scores = []\nfor train_idx, val_idx in tscv.split(X_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n    ridge.fit(X_tr, y_tr)\n    y_pred = ridge.predict(X_val)\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    ridge_cv_scores.append(rmse)\n\n# 全訓練データで再学習\nridge.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ridge回帰の交差検証結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_mean_rmse = np.mean(ridge_cv_scores)\nridge_std_rmse = np.std(ridge_cv_scores)\n\nprint(f\"CV RMSE (平均): {ridge_mean_rmse:.2f}\")\nprint(f\"CV RMSE (標準偏差): {ridge_std_rmse:.2f}\")\nprint(f\"各Fold: {[f'{s:.2f}' for s in ridge_cv_scores]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. モデリング - LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optunaによるハイパーパラメータチューニング\ndef objective(trial):\n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n    }\n\n    tscv_inner = TimeSeriesSplit(n_splits=5)\n    cv_scores = []\n\n    for train_idx, val_idx in tscv_inner.split(X_train):\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        train_data = lgb.Dataset(X_tr, label=y_tr)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n\n        model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=1000,\n            valid_sets=[val_data],\n            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n        )\n\n        y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n        cv_scores.append(rmse)\n\n    return np.mean(cv_scores)\n\n# 最適化実行\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\n\nbest_params = study.best_params\nbest_params.update({\n    'objective': 'regression',\n    'metric': 'rmse',\n    'verbosity': -1,\n    'boosting_type': 'gbdt'\n})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 最良パラメータで再学習\ntscv = TimeSeriesSplit(n_splits=5)\nlgb_cv_scores = []\n\nfor train_idx, val_idx in tscv.split(X_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n    train_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n\n    model = lgb.train(\n        best_params,\n        train_data,\n        num_boost_round=1000,\n        valid_sets=[val_data],\n        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n    )\n\n    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    lgb_cv_scores.append(rmse)\n\n# 全訓練データで最終モデルを訓練\ntrain_data_full = lgb.Dataset(X_train, label=y_train)\nlgb_model = lgb.train(\n    best_params,\n    train_data_full,\n    num_boost_round=1000\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LightGBMの交差検証結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb_mean_rmse = np.mean(lgb_cv_scores)\nlgb_std_rmse = np.std(lgb_cv_scores)\n\nprint(f\"CV RMSE (平均): {lgb_mean_rmse:.2f}\")\nprint(f\"CV RMSE (標準偏差): {lgb_std_rmse:.2f}\")\nprint(f\"各Fold: {[f'{s:.2f}' for s in lgb_cv_scores]}\")\nprint()\nprint(\"最適化されたハイパーパラメータ:\")\nfor k, v in best_params.items():\n    if k not in ['objective', 'metric', 'verbosity', 'boosting_type']:\n        print(f\"  - {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. モデル比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデル比較用データフレーム\ncomparison_df = pl.DataFrame({\n    \"Model\": [\"Ridge\", \"LightGBM\"],\n    \"CV RMSE\": [ridge_mean_rmse, lgb_mean_rmse]\n})\n\n# 比較チャート\ncomparison_chart = alt.Chart(comparison_df.to_pandas()).mark_bar().encode(\n    alt.X(\"Model:N\", title=\"モデル\"),\n    alt.Y(\"CV RMSE:Q\", title=\"RMSE\"),\n    alt.Color(\"Model:N\", legend=None),\n    tooltip=[\"Model\", alt.Tooltip(\"CV RMSE:Q\", format=\".2f\")]\n).properties(\n    width=400,\n    height=300,\n    title=\"モデル性能比較（CV RMSE）\"\n)\n\ncomparison_chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量重要度\nimportance = lgb_model.feature_importance(importance_type='gain')\nimportance_df = pl.DataFrame({\n    \"Feature\": feature_cols,\n    \"Importance\": importance\n}).sort(\"Importance\", descending=True)\n\n# 重要度チャート\nimportance_chart = alt.Chart(importance_df.to_pandas()).mark_bar().encode(\n    alt.X(\"Importance:Q\", title=\"重要度\"),\n    alt.Y(\"Feature:N\", title=\"特徴量\", sort=\"-x\"),\n    alt.Color(\"Importance:Q\", legend=None, scale=alt.Scale(scheme=\"viridis\")),\n    tooltip=[\"Feature\", alt.Tooltip(\"Importance:Q\", format=\".2f\")]\n).properties(\n    width=500,\n    height=400,\n    title=\"LightGBM特徴量重要度\"\n)\n\nimportance_chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 予測とSubmission生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBMで予測\ny_pred = lgb_model.predict(X_test)\n\n# 負の値を0にクリップ（販売数は負にならない）\ny_pred = np.maximum(y_pred, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# submission.csv生成\n# 日付フォーマット: yyyy-m-d（1桁の日は0埋めしない）\ndates = df_test_filled[\"datetime\"].to_list()\n\n# y値を整数に丸める\npredictions_int = [int(round(p)) for p in y_pred]\n\nsubmission_df = pd.DataFrame({\n    \"datetime\": dates,\n    \"y\": predictions_int\n})\n\n# 保存（ヘッダーなし）\nsubmission_path = Path(\"../submission.csv\")\nsubmission_df.to_csv(submission_path, index=False, header=False)\n\nprint(f\"Submission生成完了\")\nprint(f\"ファイルパス: {submission_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Submission内容のプレビュー"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission_df.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}